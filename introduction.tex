\section{Introduction}

%\IEEEPARstart{M}{any}
Several number systems have been proposed alternatively to IEEE-754 standards \cite{754} for deep learning. Some of them have been used in many different fields of Digital Signal Processing (DSP) and other specific applications, namely for and to process several types of neural networks (e.g. Fully-connected layers, Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN)).

\subsection{Examples of Number Systems For Deeplearning}

An example of a non-conventional number systems is the Posit number system, which is known also as UNUM III \cite{Gustafson2017}. Posit was introduced as an advanced hardware-friendly number system that overpasses IEEE standards as a system for general-purpose arithmetic. It also allows to provide faster versions of functions used in neural networks, such as the sigmoid function\footnote{Sigmoid function $\left(\sigma(x) = \frac{1}{1 + e^{-1}}\right)$ is an activation function, the $\tanh$ function is widely used and it is a scaled and shifted version of the Sigmoid function $\left(\tanh(x) = 2 \sigma(2x) -1\right)$.}.

Some suggested other number systems shrink the long carry to achieve faster computation than the conventional number systems such as Logarithmic Number Systems (LNS) \cite{Kingsbury1971} and Residual Number System (RNS) \cite{Garner1959}. The RNS has been being used in many DSP applications \cite{Cardarilli2007,Chaves2003,Claudio1995,DiClaudio1990,Jullien1987} and other extensive computational applications like asymmetric (public-key) cryptography \cite{Sousa2016}. RNS was used to provide energy-saving units in Convolution Neural Networks (CNN) \cite{Samimi2020}.

LNS \cite{Kingsbury1971,Alexopoulos1975,Lee1977} has been used in many applications, including also DSP \cite{Dimitrov2001,Lewis1995}. Recently it has been used in to design CNNs, in order to provide high accuracy in training using significantly smaller bit length \cite{Miyashita2016,Juang2019}.

\subsection{Why The Julia Programming Language}

Julia \cite{Julia,Bezanson2017} is a high-level programming language designed for numerical and scientific computation, well suited for data science. It provides an unconventional way of defining primitive types at hardware level (with number of bits predefined). All data types of Julia are defined, designed and implemented using only native Julia\footnote{{Float16, Float32, Float64} represent the IEEE Floating types in Julia. {Int128, Int16, Int32, Int64, Int8} are the conventional Signed Integers. Similarly {UInt128, UInt16, UInt32, UInt64, UInt8} are the conventional Unsigned integers.}.

Moreover, Julia provides a novel way of handling \emph{multiple dispatch} \cite{WikiMultipleDispatch} concept in programming languages \cite{JuliaMehtods}. In a nutshell, Multiple Dispatch is the ability of under a single name different processes (methods) are accommodated based on its argument(s). Examples of multiple dispatch are the primitive operations (addition, subtraction, multiplication and division) as illustrated in Listing~\ref{list:md}.

\begin{listing}[H]
\begin{minted}{julia}
julia> aInt, bInt = 1, 2; #these are Integers

julia> aF, bF = 1.0, 2.0; #there are Floats

julia> aInt + bF #this will call the method +(::Integer, ::Float64) note the result is in Float64
3.0
\end{minted}
\caption{Multiple Dispatch Example}\label{list:md}
\end{listing}

Note how the result in Listing~\ref{list:md} was promoted to be in \mintinline{julia}{Float64}, because of Julia special promotion functions \footnote{\mintinline[fontsize=\footnotesize ]{julia}{promote_rule(::Type{Integer}, ::Type{Float64}) = Float64}}. This means that functions can be used without making any modification to a package, being only required to define methods of those functions for the new type. For instance, functions such as trigonometric functions or hyperbolic functions as by default provided by Julia for its primitive types including the IEEE-754, can be simply defined for a new number system, as it will be detailed in subsection~\ref{subsec:saa}.

\textbf{Divide and conquer} is an essential approach that facilitates the focus on smaller pieces of a development process. It divides a system into layers, each layer is easily analyzed and improved. Hence, this property of Julia (Multiple Dispatch) makes it easier to individualize different steps, and then integrate them in a separated process. This means that less time is spent on editing and modifying, and more time remains for designing, testing and developing. The upcoming sections will present the methods and functions of NumNN.jl with which any new number system should be defined beforehand.

Furthermore, Julia provides a native support for parallel operations, namely co-routines, multi-threads and multi-core. Mostly, no new code is needed for parallel operations, the same code with macros can be used to process in parallel. In the same way, for-loops in Julia are as fast as for-loops in C programming language. 
