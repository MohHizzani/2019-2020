\section{Introduction}

\IEEEPARstart{M}{any} new and old number systems has been introduced as a better alternative to IEEE-754 standards\cite{754} in the field of Deeplearning.

\subsection{Examples of Number Systems Used in Deeplearning}

An example of novel number systems is the Posit number system\cite{Gustafson2017}, which is known also as UNUM III. Posit was introduced as an advanced number system that overpass IEEE standards as a hardware-friendly system for general-purpose computation arithmetic operations that provides some faster versions of functions used in neural networks such as the Sigmoid function\footnote{Sigmoid function $\left(\sigma(x) = \frac{1}{1 + e^{-1}}\right)$ is rarely used as an activation function. However, $\tanh$ function is widely used and it is a scaled and shifted version of the Sigmoid function $\left(\tanh(x) = 2 \sigma(2x) -1\right)$.}. Some suggests to use previously known number systems that can be modified to perform much faster computation than the conventional IEEE-754. Residual Number System (RNS) \cite{Garner1959} were used in many DSP applications. RNS was used as a potential number system to provide energy saver units in Convolution Neural Networks (CNN) \cite{Miyashita2016}. Another number system is the Logarithmic Number System (LNS) \cite{Kingsbury1971,Alexopoulos1975,Lee1977} which is being developed to be used in CNN to provide higher accuracy in training using much smaller bit length \cite{Miyashita2016}.

\subsection{Whe Julia?}
