%\documentclass[onecolumn,draftcls,12pt,conference]{IEEEtran}
\documentclass{article}
\usepackage[nonatbib]{neurips_2020}
%\usepackage{natbib}
\usepackage[utf8]{inputenc}

\usepackage{IEEEtrantools}
%\usepackage{standalone}
%\include{examplepreamble}
%\standaloneconfig{}
%\usepackage[subpreambles=true]{standalone}
\usepackage{import}
\usepackage{framed}

\usepackage[hidelinks]{hyperref}
%\usepackage{cite}

\usepackage{caption}
%\usepackage{graphicx}
%\usepackage{float}
%\usepackage{listing}
\usepackage[dvipsnames]{xcolor}
\colorlet{LGray}{Gray!10!}
%%% for code wraping
\usepackage{minted}
\usemintedstyle{colorful}
\setminted[julia]{frame=lines,rulecolor=MidnightBlue,bgcolor=LGray,fontsize=\footnotesize ,breaklines}
\usepackage{tikz}
\usetikzlibrary{mindmap}

\usepackage{pmboxdraw}
%\usepackage{qtree}
%\usepackage{subcaption}



\title{NumNN.jl Deeplearning Package for Rapid Testing and Simulating Number Systems on Neural Networks}

\author{%\IEEEauthorblockN
	{Mohammad~Hizzani}\\
	%\IEEEauthorblockA
	{INESC-ID\\ Instituto Superior Técnico\\ Universidade de Lisboa\\
		Email: \href{mailto:moh.hizzani@gmail.com}{moh.hizzani@gmail.com}}
	\AND
	%\IEEEauthorblockN
	{Leonel Sousa}\\
	%\IEEEauthorblockA
	{INESC-ID\\ Instituto Superior Técnico\\ Universidade de Lisboa\\
		Email: \href{mailto:las@inesc-id.pt}{las@inesc-id.pt}}
	%Email: some@sdf.com}
}



\begin{document}
	\maketitle

	\begin{abstract}
		The development of Deeplearning models and techniques approach an extensive need for hardware support, where many new models have deep architectures (in terms of number of layers and number of computation per layer whether they are nodes or channels). As well as, they are using big data for training, in addition to need to tune the hyper parameters which may require the repetition of the whole training process or part of it again and again. Thus, many number systems were introduced as an alternative to the IEEE floating-point formats as hardware-friendly systems which are faster and/or more accurate in computation. However, the hardware design and verification process is complex and expensive. Hence, these number systems should be tested in simulation environments before moving forward. And because most deeplearning frameworks and libraries target AI production, they only support the IEEE formats. This paper represents a package was designed with rapid prototyping and experimenting number systems in mind. It provides a agile way of designing, training and evaluating a deeplearning (neural network) model with any number system(s).
	\end{abstract}

	\input{introduction}
	
	\input{body}
	
	\input{futurework}
%	\includestandalone[subpreambles=true]{00-FCLayer-FashionMNIST/00-FCLayer-FashionMNIST}
	%\input{appendices}
	
	\bibliographystyle{IEEEtran}
	%\bibliographystyle{plainnat}
	\bibliography{main}
\end{document}
